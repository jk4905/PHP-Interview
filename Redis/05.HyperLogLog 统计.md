#### 05.HyperLogLog 统计
---

为了很好说明这个数据结构的作用，举个例子：通常会有这样的需求，统计网站上每个网页的 PV 和 UV。

* PV：采用 Redis 的 String 来计数，每个网页分配一个独立计数器就行。来一个请求就执行 incr 一次。
* UV：UV 与 PV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。每个网页都需要带上用户的 id 来记录。通常想到的是使用 Set 数据结构。但当 UV 特别大的时候，Set 就特别浪费空间。那么就需要更好的方案来解决。

使用 Redis 自带的 HyperLogLog 数据结构来统计。它是用来做基数统计的算法，HyperLogLog 的

优点：在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。

在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。


> 什么是基数?
> 比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。

HyperLogLog 有三个指令：
* pfadd key element [element ...] 添加指定元素到 HyperLogLog 中。
* PFCOUNT key [key ...] 统计指定元素的基数估计值。
* PFMERGE destkey sourcekey [sourcekey ...] 合并多个基数值成为一个新的基数值。

```lua
127.0.0.1:6379> pfadd pv user1 user2 user3 user4
(integer) 1
127.0.0.1:6379> pfcount pv
(integer) 4
127.0.0.1:6379> pfadd pv user1 user2 user3 user4
(integer) 0
127.0.0.1:6379> pfcount pv
(integer) 4
127.0.0.1:6379> pfadd uv user5 user6 user7 user8 user9 user10
(integer) 1
127.0.0.1:6379> pfcount uv
(integer) 6
127.0.0.1:6379> pfmerge  mergeV pv uv # 合并
OK
127.0.0.1:6379> pfcount mergeV # 发现得到 10
(integer) 10
```